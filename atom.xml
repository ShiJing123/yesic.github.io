<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tech-Port</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-06-09T17:50:18.698Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>yesic</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[NIPS 2017]Learning Hierarchical Information Flow with Recurrent Neural Modules</title>
    <link href="http://yoursite.com/2018/06/10/NIPS-2017-Learning-Hierarchical-Information-Flow-with-Recurrent-Neural-Modules/"/>
    <id>http://yoursite.com/2018/06/10/NIPS-2017-Learning-Hierarchical-Information-Flow-with-Recurrent-Neural-Modules/</id>
    <published>2018-06-09T17:35:44.000Z</published>
    <updated>2018-06-09T17:50:18.698Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文受到新脑皮质（neocortical）通信方式的启发，提出了ThalNet。新脑皮质通信方式有两种，一种是直连，另一种是通过丘脑（thalamus）。论文受到第二种通信方式的启发，构建多个循环神经模块，将所有模块的特征发送到一个路由中心，使得模块在多个时间步能够共享特征。模型展示了模块对输入数据的链式处理，学习了层次化的路由信息，并且模型包含了前馈神经网络、跳跃连接、反馈连接等结构。</p></blockquote><a id="more"></a><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p><img src="https://github.com/yesic/pic/blob/master/hif/hif-1.jpg?raw=true" alt=""></p><p>论文构建的模型包括四个模块，模块$f^1$接受input， $f^2$，$f^3$为侧模块，$f^4$负责输出，每个模块$f$可以是全连接层、GRU、LSTM等。对于每一时刻t，每个模块将其特征$\phi_t$发给路由中心 $\Phi$，其中每个模块特征由上下文$c_t$和一个可以选择的输入 $x_t$决定。对于下一时刻的上下文 $c_{t+1}$，每个模块通过阅读机制（read mechanism）选择性地读取路由中心$\Phi$的特征。对于每个模块的特征计算，上下文计算，路由中心，模型输出式子见下图。</p><p><img src="https://github.com/yesic/pic/blob/master/hif/hif-2.jpg?raw=true" alt=""></p><p>阅读机制包括两种：静态阅读，动态阅读。静态阅读只取决于 $\Phi$，即$r^i(\Phi)$，而动态阅读不仅取决于 $\Phi$，还取决于当前模块的特征，即 $r^i(\Phi,\phi^i)$。</p><p>文中给出了四种阅读方法，其中weight normalization、Fast softmax比较稳定，效果比较好。 </p><p><img src="https://github.com/yesic/pic/blob/master/hif/hif-3.jpg?raw=true" alt=""><img src="https://github.com/yesic/pic/blob/master/hif/hif-4.jpg?raw=true" alt=""></p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>论文在三个任务上做了实验， Sequential Permuted MNIST、Sequential CIFAR-10、Text8 Language Modeling。其中前两个是图像的延迟预测，即将图像的像素每一行看作一个时刻，在输入最后一个时刻时预测出图像的类别，第三个任务是输入每个character，预测下一个character。 </p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文受到新脑皮质（neocortical）通信方式的启发，提出了ThalNet。新脑皮质通信方式有两种，一种是直连，另一种是通过丘脑（thalamus）。论文受到第二种通信方式的启发，构建多个循环神经模块，将所有模块的特征发送到一个路由中心，使得模块在多个时间步能够共享特征。模型展示了模块对输入数据的链式处理，学习了层次化的路由信息，并且模型包含了前馈神经网络、跳跃连接、反馈连接等结构。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="NIPS" scheme="http://yoursite.com/categories/paper-notes/NIPS/"/>
    
      <category term="2017" scheme="http://yoursite.com/categories/paper-notes/NIPS/2017/"/>
    
    
      <category term="hierarchical" scheme="http://yoursite.com/tags/hierarchical/"/>
    
  </entry>
  
  <entry>
    <title>[ICLR 2018]Hierarchical Representations for Efficient Architecture Search</title>
    <link href="http://yoursite.com/2018/06/10/ICLR-2018-Hierarchical-Representations-for-Efficient-Architecture-Search/"/>
    <id>http://yoursite.com/2018/06/10/ICLR-2018-Hierarchical-Representations-for-Efficient-Architecture-Search/</id>
    <published>2018-06-09T17:24:00.000Z</published>
    <updated>2018-06-09T17:50:34.382Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文结合了一种新型层次化遗传表示体系（hierarchical genetic representation scheme），可以模仿人类专家常用的模块化设计模式，支持复杂的拓扑结构。分别在CIFAR-10和ImageNet上获得了top-1错误率为3.6%和20.3%。 </p></blockquote><a id="more"></a><p>在这项工作中，作者通过强加一个层次化的网络来限制搜索空间结构，允许每层是一些灵活的网络拓扑结构（有向无环图）。底层是一些基本操作，例如卷积，池化等，更高层的计算图，或者modif，是由低层modif作为它们的构建块来组成，最高层的modif通过堆叠形成最终的网络结构。如下图所示。</p><p><img src="https://github.com/yesic/pic/blob/master/hgrs/hgrs-1.jpg?raw=true" alt=""></p><p>作者通过进化搜索或者随机搜索来发现层次化结构。基于遗传算法，作者定义了一些变异（mutation），每次选择某一层的某个motif的某条边发生变异，这可以使得modif的结构发生改变（删除，添加，修改），将验证集的准确率作为fitness。</p><p>在实验中，提出的搜索框架只学习cell的结构，而不是整个模型。原因是这样能够快速计算fitness，然后可以将对应的genotype转移到大的模型，也就是用更少的cell计算fitness，更多的cell评估模型。下图是使用框架搜索优化过的cell构建的图像分类模型。</p><p><img src="https://github.com/yesic/pic/blob/master/hgrs/hgrs-2.jpg?raw=true" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文结合了一种新型层次化遗传表示体系（hierarchical genetic representation scheme），可以模仿人类专家常用的模块化设计模式，支持复杂的拓扑结构。分别在CIFAR-10和ImageNet上获得了top-1错误率为3.6%和20.3%。 &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="ICLR" scheme="http://yoursite.com/categories/paper-notes/ICLR/"/>
    
      <category term="2018" scheme="http://yoursite.com/categories/paper-notes/ICLR/2018/"/>
    
    
      <category term="hierarchical" scheme="http://yoursite.com/tags/hierarchical/"/>
    
  </entry>
  
  <entry>
    <title>[IJCAI 2018]A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification</title>
    <link href="http://yoursite.com/2018/06/10/IJCAI-2018-A-Hierarchical-End-to-End-Model-for-Jointly-Improving-Text-Summarization-and-Sentiment-Classification/"/>
    <id>http://yoursite.com/2018/06/10/IJCAI-2018-A-Hierarchical-End-to-End-Model-for-Jointly-Improving-Text-Summarization-and-Sentiment-Classification/</id>
    <published>2018-06-09T16:44:10.000Z</published>
    <updated>2018-06-09T17:20:35.882Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文提出了一种层次化端到端模型，整合了文本摘要生成和情感分类任务 。</p></blockquote><a id="more"></a><blockquote><p>模型借鉴来源：<a href="https://yesic.github.io/2018/06/09/NAACL-2016-Hierarchical-Attention-Networks-for-Document-Classification/" target="_blank" rel="noopener">Hierarchical Attention Networks for Document Classification</a></p></blockquote><hr><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p>给定样本$(x^i,y^i,l^i)$，包含了文本，摘要，情感标签，同时进行摘要生成和情感分类。其中$L_i$为文本的单词数， $M_i$为摘要的单词数。</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-1.jpg?raw=true" alt=""><br><br></div><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>模型包括三部分：text encoder，summary decoder，sentiment classifier</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-2.jpg?raw=true" alt=""><br><br></div><h5 id="text-encoder"><a href="#text-encoder" class="headerlink" title="text encoder"></a>text encoder</h5><ol><li>使用双向LSTM作为encoder，产生上下文信息$h={h_1,h_2,…,h_L}$</li></ol><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-3.jpg?raw=true" alt=""></div><h5 id="summary-decoder"><a href="#summary-decoder" class="headerlink" title="summary decoder"></a>summary decoder</h5><p>Summary decoder包括三部分：单向LSTM，multi-view attention，word generator</p><ol><li><p>利用单向LSTM产生decoder的隐藏层输出$s_t$</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-4.jpg?raw=true" alt=""></div></li><li><p>利用multi-view attention生成摘要向量$\mathbf{v}^{(c)}$和情感向量$\mathbf{v}^{(t)}$，multi-view attention其实就是两个独立的global attention。摘要向量$\mathbf{v}^{(c)}$生成如下：</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-5.jpg?raw=true" alt=""></div></li><li><p>根据摘要向量 $\mathbf{v}^{(c)}$，利用生成摘要中的每个词。 </p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-6.jpg?raw=true" alt=""></div></li></ol><h5 id="sentiment-classifier"><a href="#sentiment-classifier" class="headerlink" title="sentiment classifier"></a>sentiment classifier</h5><ol><li><p>将所有时间步的情感向量 $\mathbf{v}^{(t)}$收集起来</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-7.jpg?raw=true" alt=""></div></li><li><p>为了获得原文本的上下文信息，使用highway机制，将上下文信息h作为分类器输入的一部分，r为情感分类的输入向量</p><div align="center"><br><br><img src="https://github.com/yesic/pic/blob/master/man/man-8.jpg?raw=true" alt=""></div></li></ol><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>作者在亚马逊在线评论数据集上做了实验，在和其他模型的对比上均获得了最好的结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文提出了一种层次化端到端模型，整合了文本摘要生成和情感分类任务 。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="IJCAI" scheme="http://yoursite.com/categories/paper-notes/IJCAI/"/>
    
      <category term="2018" scheme="http://yoursite.com/categories/paper-notes/IJCAI/2018/"/>
    
    
      <category term="encoder decoder" scheme="http://yoursite.com/tags/encoder-decoder/"/>
    
      <category term="text summarization" scheme="http://yoursite.com/tags/text-summarization/"/>
    
      <category term="sentiment classification" scheme="http://yoursite.com/tags/sentiment-classification/"/>
    
  </entry>
  
  <entry>
    <title>[NAACL 2016]Hierarchical Attention Networks for Document Classification</title>
    <link href="http://yoursite.com/2018/06/10/NAACL-2016-Hierarchical-Attention-Networks-for-Document-Classification/"/>
    <id>http://yoursite.com/2018/06/10/NAACL-2016-Hierarchical-Attention-Networks-for-Document-Classification/</id>
    <published>2018-06-09T16:19:35.000Z</published>
    <updated>2018-06-09T17:19:33.854Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文提出了一种层次化的注意力网络用于文本分类，模型有两个特点：1）它有一个层次化的结构，反映了文本的层次化结构（由词组成句；由句组成文本）；2）它有两个level的注意力机制，分别是word-level和sentence-level。 </p></blockquote><a id="more"></a><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>模型由四部分组成：word encoder，word attention，sentence encoder，sentence attention</p><p><img src="https://github.com/yesic/pic/blob/master/han/han-1.jpg?raw=true" alt=""></p><h5 id="word-encoder"><a href="#word-encoder" class="headerlink" title="word encoder"></a>word encoder</h5><ol><li><p>对每个词进行word embedding，在通过双向GRU提取隐藏层状态，将两个方向的隐藏层状态拼接， $w_{it}$为文本第i个句子的第t个词 。</p><p><img src="https://github.com/yesic/pic/blob/master/han/han-2.jpg?raw=true" alt=""></p></li></ol><p><img src="https://github.com/yesic/pic/blob/master/han/han-3.jpg?raw=true" alt=""></p><h5 id="word-attention"><a href="#word-attention" class="headerlink" title="word attention"></a>word attention</h5><ol><li>对每个句子的所有词做attention，然后计算每个句子向量$s_i$：</li></ol><p><img src="https://github.com/yesic/pic/blob/master/han/han-4.jpg?raw=true" alt=""></p><h5 id="sentence-encoder"><a href="#sentence-encoder" class="headerlink" title="sentence encoder"></a>sentence encoder</h5><ol><li><p>和word encoder方式一样，利用双向GRU提取每个句子向量$s_i$的信息，然后将两个方向的隐藏层状态拼接</p><p><img src="https://github.com/yesic/pic/blob/master/han/han-5.jpg?raw=true" alt=""></p><p><img src="https://github.com/yesic/pic/blob/master/han/han-6.jpg?raw=true" alt=""></p></li></ol><h5 id="sentence-attention"><a href="#sentence-attention" class="headerlink" title="sentence attention"></a>sentence attention</h5><p>和word attention方式一样，对文本的每个句子做attention，然后计算文本向量v，将v用softmax分类。</p><p><img src="https://github.com/yesic/pic/blob/master/han/han-7.jpg?raw=true" alt=""></p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>作者在6个大规模文本分类数据集上做了实验，和众多SVM，CNN，LSTM比较均获得了最好的结果。 </p><p><img src="https://github.com/yesic/pic/blob/master/han/han-8.jpg?raw=true" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文提出了一种层次化的注意力网络用于文本分类，模型有两个特点：1）它有一个层次化的结构，反映了文本的层次化结构（由词组成句；由句组成文本）；2）它有两个level的注意力机制，分别是word-level和sentence-level。 &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="NAACL" scheme="http://yoursite.com/categories/paper-notes/NAACL/"/>
    
      <category term="2016" scheme="http://yoursite.com/categories/paper-notes/NAACL/2016/"/>
    
    
      <category term="hierarchical" scheme="http://yoursite.com/tags/hierarchical/"/>
    
      <category term="encoder decoder" scheme="http://yoursite.com/tags/encoder-decoder/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
      <category term="document classification" scheme="http://yoursite.com/tags/document-classification/"/>
    
  </entry>
  
  <entry>
    <title>[arxiv 2018]Hierarchical Attention-Based Recurrent Highway Networks for Time Series Prediction</title>
    <link href="http://yoursite.com/2018/06/09/arxiv-2018-Hierarchical-Attention-Based-Recurrent-Highway-Networks-for-Time-Series-Prediction/"/>
    <id>http://yoursite.com/2018/06/09/arxiv-2018-Hierarchical-Attention-Based-Recurrent-Highway-Networks-for-Time-Series-Prediction/</id>
    <published>2018-06-09T14:21:15.000Z</published>
    <updated>2018-06-09T17:19:27.084Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文提出了一种可以端到端学习的深度学习模型，Hierarchical Attention-Based Recurrent Highway Networks(HARNN)，可以将外部序列的时空特征提取和目标序列的时空动态建模结合到一个简单的框架。</p></blockquote><a id="more"></a><blockquote><p>论文模型借鉴来源：<a href="https://yesic.github.io/2018/06/09/IJCAI-2017-A-Dual-Stage-Attention-Based-Recurrent-Neural-Network-for-Time-Series-Prediction/" target="_blank" rel="noopener">A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction</a></p></blockquote><hr><h4 id="模型贡献"><a href="#模型贡献" class="headerlink" title="模型贡献"></a>模型贡献</h4><ul><li>利用卷积网络学习外部输入（<strong>x</strong>）中变量之间的空间特征。接着利用RHN（recurrent highway network）在不同层构建不同的语义，建模时序动态。</li><li>提出层次化注意力机制。</li><li>在获得高准确率的同时，可以捕获时间序列中的突然振荡或者变动。</li></ul><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p>时间序列预测，给定<code>1~T-1</code>时刻的目标序列以及<code>1~T-1</code>时刻的外部序列，预测T时刻的目标值。</p><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>encoder和decoder均使用多层RHN，在encoder使用卷积网络提取外部序列的时空特征，在decoder使用层次化注意力机制对时序依赖动态建模。</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-1.jpg?raw=true" alt=""></p><h5 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h5><ol><li><p>将外部输入$(\mathbf{x_1,x_2,…,x_{T-1}})$通过几层卷积、池化操作后输给一个全连接层，得到一个特征向量 $(\mathbf{w_1,w_2,…,w_{T-1}})$ </p></li><li><p>利用RHN对<code>encoder-1</code>中的特征向量进行时序动态建模。$\mathbf{h}_t^{[k]}$表示第k层第t时刻的隐藏层状态 </p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-2.jpg?raw=true" alt=""></p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-3.jpg?raw=true" alt=""></p></li></ol><h5 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h5><ol><li><p>多层注意力机制：在t时刻，对encoder每一层的1~T-1时刻的隐藏层状态做attention。其中$\mathbf{s_{t-1}}=\mathbf{s}_{t-1}^{[k]}$ ，t-1时刻decoder第k层隐藏层状态。</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-4.jpg?raw=true" alt=""></p></li><li><p>则第k层第t时刻的子上下文$\mathbf{d}_t^{[k]}$为</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-5.jpg?raw=true" alt=""></p><p>将t时刻所有层的子上下文拼接，得到t时刻的上下文$\mathbf{d}_t$：</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-6.jpg?raw=true" alt=""></p></li><li><p>更新decoder输入$\mathbf{y}_t$为$\mathbf{\tilde{y}_t}$：</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-7.jpg?raw=true" alt=""></p></li><li><p>解码器RHN第k层隐藏层状态$\mathbf{s}_{t}^{[k]}$：</p><p> <img src="https://github.com/yesic/pic/blob/master/harnn/harnn-8.jpg?raw=true" alt=""></p></li><li><p>第T时刻预测值$\mathbf{\hat{y}_T}$：</p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-9.jpg?raw=true" alt=""></p></li></ol><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>作者在三个数据集上和ARIMA，LSTM，GRU，DA-RNN模型比较，均获得最好的结果。 </p><p><img src="https://github.com/yesic/pic/blob/master/harnn/harnn-10.jpg?raw=true" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文提出了一种可以端到端学习的深度学习模型，Hierarchical Attention-Based Recurrent Highway Networks(HARNN)，可以将外部序列的时空特征提取和目标序列的时空动态建模结合到一个简单的框架。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="arxiv" scheme="http://yoursite.com/categories/paper-notes/arxiv/"/>
    
      <category term="2018" scheme="http://yoursite.com/categories/paper-notes/arxiv/2018/"/>
    
    
      <category term="hierarchical" scheme="http://yoursite.com/tags/hierarchical/"/>
    
      <category term="time series prediction" scheme="http://yoursite.com/tags/time-series-prediction/"/>
    
      <category term="encoder decoder" scheme="http://yoursite.com/tags/encoder-decoder/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>[IJCAI 2017]A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction</title>
    <link href="http://yoursite.com/2018/06/09/IJCAI-2017-A-Dual-Stage-Attention-Based-Recurrent-Neural-Network-for-Time-Series-Prediction/"/>
    <id>http://yoursite.com/2018/06/09/IJCAI-2017-A-Dual-Stage-Attention-Based-Recurrent-Neural-Network-for-Time-Series-Prediction/</id>
    <published>2018-06-09T10:46:59.000Z</published>
    <updated>2018-06-09T17:19:21.344Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>论文提出了基于注意力机制的两阶段循环神经网络（DA-RNN），在第一阶段（encoder），引入input attention mechanism对每一时刻的外部输入自适应性地提取相关性；在第二阶段（decoder），引入temporal attention mechanism捕获encoder的长期时序依赖信息。</p></blockquote><a id="more"></a><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p>时间序列预测，给定<code>1~T-1</code>时刻的目标序列以及<code>1~T-1</code>时刻的外部序列，预测T时刻的目标值。</p><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-1.jpg?raw=true" alt="DA-RNN"></p><h5 id="encoder"><a href="#encoder" class="headerlink" title="encoder"></a>encoder</h5><ol><li><p>使用LSTM作为encoder和decoder，其中状态更新如下 ：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-2.jpg?raw=true" alt=""></p></li><li><p>引入input attention mechanism：对每一时刻$\mathbf{X_t}$的n维变量使用attention</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-3.jpg?raw=true" alt=""> </p></li><li><p>使用$\alpha_t^k$对$\mathbf{X_t}$加权求和，更新$\mathbf{X_t}$：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-4.jpg?raw=true" alt=""></p></li><li><p>使用$\tilde{X_t}$更新<code>1</code>中的状态方程：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-5.jpg?raw=true" alt=""></p></li></ol><h5 id="decoder"><a href="#decoder" class="headerlink" title="decoder"></a>decoder</h5><ol><li><p>引入temporal attention mechanism：在decoder的第t时刻，对encoder所有隐藏层状态做attention </p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-6.jpg?raw=true" alt=""></p></li><li><p>计算t时刻的上下文向量$\mathbf{c_t}$：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-8.jpg?raw=true" alt=""></p></li><li><p>利用$\mathbf{c_t}$更新目标序列的输入值$\mathbf{y_{t-1}}$为$\mathbf{\tilde{y}_{t-1}}$：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-7.jpg?raw=true" alt=""></p></li><li><p>更新第t时刻decoder的隐藏层状态$\mathbf{d_t}$：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-9.jpg?raw=true" alt=""></p><p>其中$f_2$的更新状态方程如<code>encoder-1</code>：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-10.jpg?raw=true" alt=""></p></li></ol><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-11.jpg?raw=true" alt=""></p><ol><li><p>则第t时刻的预测值$\mathbf{\hat{T}_t}$为：</p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-12.jpg?raw=true" alt=""></p></li></ol><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>作者在两个数据集上和ARIMA，NARX RNN，Encoder-Decoder，Attention RNN模型进行了比较，均获得了最好的结果。 </p><p><img src="https://github.com/yesic/pic/blob/master/dual/dual-13.jpg?raw=true" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;论文提出了基于注意力机制的两阶段循环神经网络（DA-RNN），在第一阶段（encoder），引入input attention mechanism对每一时刻的外部输入自适应性地提取相关性；在第二阶段（decoder），引入temporal attention mechanism捕获encoder的长期时序依赖信息。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="paper notes" scheme="http://yoursite.com/categories/paper-notes/"/>
    
      <category term="IJCAI" scheme="http://yoursite.com/categories/paper-notes/IJCAI/"/>
    
      <category term="2017" scheme="http://yoursite.com/categories/paper-notes/IJCAI/2017/"/>
    
    
      <category term="hierarchical" scheme="http://yoursite.com/tags/hierarchical/"/>
    
      <category term="time series prediction" scheme="http://yoursite.com/tags/time-series-prediction/"/>
    
      <category term="encoder decoder" scheme="http://yoursite.com/tags/encoder-decoder/"/>
    
      <category term="attention" scheme="http://yoursite.com/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/06/08/hello-world/"/>
    <id>http://yoursite.com/2018/06/08/hello-world/</id>
    <published>2018-06-08T13:21:13.976Z</published>
    <updated>2018-06-09T17:33:29.441Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.<br><a id="more"></a></p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;br&gt;
    
    </summary>
    
      <category term="test" scheme="http://yoursite.com/categories/test/"/>
    
    
  </entry>
  
</feed>
